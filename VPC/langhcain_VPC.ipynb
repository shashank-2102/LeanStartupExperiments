{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/agent_supervisor.ipynb \\\n",
    "https://python.langchain.com/docs/integrations/tools/tavily_search/ \\\n",
    "https://tavily.com/ \\\n",
    "https://python.langchain.com/docs/integrations/chat/openai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture --no-stderr\n",
    "#%pip install -U langgraph langchain_community langchain_anthropic langchain_experimental\n",
    "#%pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from typing import Annotated\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "#from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the keys\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.getenv(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "        #print(\"API key error\")\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "@tool\n",
    "def search_for_business_insights(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the web for business insights, market trends, and competitive analysis to help with \n",
    "    creating a Value Proposition Canvas.\n",
    "    \n",
    "    Args:\n",
    "        query: A search query related to business ideas, market analysis, customer needs, or competitors.\n",
    "        \n",
    "    Returns:\n",
    "        Relevant information from the web that can help in developing a Value Proposition Canvas.\n",
    "    \"\"\"\n",
    "    search_results = tavily_tool.invoke(query)\n",
    "    \n",
    "    # Format the results for better readability\n",
    "    formatted_results = \"## Web Search Results\\n\\n\"\n",
    "    for i, result in enumerate(search_results, 1):\n",
    "        formatted_results += f\"### Result {i}: {result.get('title', 'No Title')}\\n\"\n",
    "        formatted_results += f\"{result.get('content', 'No content available')}\\n\\n\"\n",
    "        formatted_results += f\"Source: {result.get('url', 'No URL')}\\n\\n\"\n",
    "        formatted_results += \"---\\n\\n\"\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "\n",
    "#prompt loader\n",
    "def load_prompt(file_name: str, name: str):\n",
    "    with open(f\"../prompts/{file_name}.txt\", \"r\", encoding='utf-8') as file:\n",
    "        name = file.read()\n",
    "    return name\n",
    "\n",
    "#load_prompt(\"Agent_A_test\", \"Agent_A_prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"Input_Checker\", \"VPC\", \"Output_Checker\"]\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When ypu require,\"\n",
    "    \" user input just output USER INPUT NEEDED\"\n",
    "    \" if the input is valid and input agent says ACCEPTED forward it to the vpc_agent\"\n",
    "    \" if the input agent says the input is INVALID respond with FINISH and tell the user the input is invalid.\"\n",
    ")\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VPC_prompt = load_prompt(\"prompt_VPC_CUT\", \"VPC_CUT_prompt\") + \"When you require user input (ie after your output) say USER INPUT NEEDED\"\n",
    "\n",
    "\n",
    "input_agent_prompt = load_prompt(\"Agent_A_test\", \"Agent_A_prompt\")\n",
    "\n",
    "output_agent_prompt = \"You are output agent, you are supposed to oversee whether the supervisor provides sane output answering the users' query\" + \"If the VPC agent says USER INPUT NEEDED ONLY OUTPUT'USER INPUT NEEDED'\"\n",
    "\n",
    "task_prompt = \"The user can give you a range of business ideas, normal ones like creating new types of toys to outlandish ones like organic gmo pet food for parrots. You should entertain these ideas as long as they are about the business idea and its value proposition (canvas) or VPC. If it deviates to other tasks then it is out of scope. Do not be extremely strict. If the input is INVALID say 'INVALID' and tell the user the input is invalid. Be very lenient with the user's input regaring things like the type of approaches.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_agent = create_react_agent(\n",
    "    llm, tools=[], prompt= input_agent_prompt + task_prompt\n",
    ")\n",
    "\n",
    "VPC_agent = create_react_agent(\n",
    "    llm, tools=[search_for_business_insights], prompt= VPC_prompt    \n",
    ")\n",
    "\n",
    "output_agent = create_react_agent(\n",
    "    llm, tools=[], prompt= output_agent_prompt\n",
    ")\n",
    "\n",
    "def input_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = input_agent.invoke(state)\n",
    "    \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"Input_Checker\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"VPC\",\n",
    "    )\n",
    "\n",
    "\n",
    "def VPC_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = VPC_agent.invoke(state)\n",
    "    \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"VPC\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def output_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = output_agent.invoke(state)\n",
    "    \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"Output_Checker\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"VPC\", VPC_node)\n",
    "builder.add_node(\"Input_Checker\", input_node)\n",
    "builder.add_node(\"Output_Checker\", output_node)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'supervisor': Node(id='supervisor', name='supervisor', data=supervisor(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'VPC': Node(id='VPC', name='VPC', data=VPC(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Input_Checker': Node(id='Input_Checker', name='Input_Checker', data=Input_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Output_Checker': Node(id='Output_Checker', name='Output_Checker', data=Output_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='__start__', target='supervisor', data=None, conditional=False), Edge(source='supervisor', target='Input_Checker', data=None, conditional=True), Edge(source='supervisor', target='VPC', data=None, conditional=True), Edge(source='supervisor', target='Output_Checker', data=None, conditional=True), Edge(source='supervisor', target='__end__', data=None, conditional=True), Edge(source='VPC', target='supervisor', data=None, conditional=True), Edge(source='Input_Checker', target='supervisor', data=None, conditional=True), Edge(source='Output_Checker', target='supervisor', data=None, conditional=True)])'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\display.py:1128\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1128\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'Graph'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\formatters.py:1036\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m   1033\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\display.py:1118\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m   1117\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[1;32m-> 1118\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43malways_both\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[0;32m   1120\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\display.py:1130\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'supervisor': Node(id='supervisor', name='supervisor', data=supervisor(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'VPC': Node(id='VPC', name='VPC', data=VPC(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Input_Checker': Node(id='Input_Checker', name='Input_Checker', data=Input_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Output_Checker': Node(id='Output_Checker', name='Output_Checker', data=Output_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='__start__', target='supervisor', data=None, conditional=False), Edge(source='supervisor', target='Input_Checker', data=None, conditional=True), Edge(source='supervisor', target='VPC', data=None, conditional=True), Edge(source='supervisor', target='Output_Checker', data=None, conditional=True), Edge(source='supervisor', target='__end__', data=None, conditional=True), Edge(source='VPC', target='supervisor', data=None, conditional=True), Edge(source='Input_Checker', target='supervisor', data=None, conditional=True), Edge(source='Output_Checker', target='supervisor', data=None, conditional=True)])'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'supervisor': Node(id='supervisor', name='supervisor', data=supervisor(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'VPC': Node(id='VPC', name='VPC', data=VPC(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Input_Checker': Node(id='Input_Checker', name='Input_Checker', data=Input_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Output_Checker': Node(id='Output_Checker', name='Output_Checker', data=Output_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='__start__', target='supervisor', data=None, conditional=False), Edge(source='supervisor', target='Input_Checker', data=None, conditional=True), Edge(source='supervisor', target='VPC', data=None, conditional=True), Edge(source='supervisor', target='Output_Checker', data=None, conditional=True), Edge(source='supervisor', target='__end__', data=None, conditional=True), Edge(source='VPC', target='supervisor', data=None, conditional=True), Edge(source='Input_Checker', target='supervisor', data=None, conditional=True), Edge(source='Output_Checker', target='supervisor', data=None, conditional=True)])'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\display.py:1128\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1128\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'Graph'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\formatters.py:406\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    404\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\display.py:1150\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[1;32m-> 1150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shash\\OneDrive - TU Eindhoven\\Shashank Prabhu University\\Masters DSAI\\Generative AI Research Assistant\\LeanStartupExperiments\\venv\\Lib\\site-packages\\IPython\\core\\display.py:1130\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: 'Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=<class 'langchain_core.utils.pydantic.LangGraphInput'>, metadata=None), 'supervisor': Node(id='supervisor', name='supervisor', data=supervisor(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'VPC': Node(id='VPC', name='VPC', data=VPC(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Input_Checker': Node(id='Input_Checker', name='Input_Checker', data=Input_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), 'Output_Checker': Node(id='Output_Checker', name='Output_Checker', data=Output_Checker(tags=None, recurse=True, explode_args=False, func_accepts_config=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=<class 'langchain_core.utils.pydantic.LangGraphOutput'>, metadata=None)}, edges=[Edge(source='__start__', target='supervisor', data=None, conditional=False), Edge(source='supervisor', target='Input_Checker', data=None, conditional=True), Edge(source='supervisor', target='VPC', data=None, conditional=True), Edge(source='supervisor', target='Output_Checker', data=None, conditional=True), Edge(source='supervisor', target='__end__', data=None, conditional=True), Edge(source='VPC', target='supervisor', data=None, conditional=True), Edge(source='Input_Checker', target='supervisor', data=None, conditional=True), Edge(source='Output_Checker', target='supervisor', data=None, conditional=True)])'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display graph\n",
    "display(Image(graph.get_graph()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoke the team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple(user_input: str):\n",
    "    time_start = time.time()  \n",
    "    for s in graph.stream(\n",
    "        {\"messages\": [(\"user\", user_input)]}, subgraphs=True\n",
    "    ):\n",
    "        if isinstance(s, tuple) and len(s) > 1:\n",
    "            if \"supervisor\" in s[1] and \"next\" in s[1][\"supervisor\"]:\n",
    "                print(f\"Supervisor Next: {s[1]['supervisor']['next']}\")\n",
    "                print(\"----\")\n",
    "            \n",
    "            # Extract agent messages\n",
    "            agent_data = s[1].get(\"agent\")\n",
    "            if agent_data and \"messages\" in agent_data:\n",
    "                for message in agent_data[\"messages\"]:\n",
    "                    print(f\"Agent: {message.response_metadata.get('model_name', 'Unknown')}\") #if model name is not available, print Unknown\n",
    "                    print(f\"Message: {message.content}\")\n",
    "                    time_end = time.time()\n",
    "                    print(f\"Time taken: {time_end - time_start}\")\n",
    "                    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#un_simple(\" Hi, create me a VPC for an idea on building electronic devices out of paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iter(user_input: str):\n",
    "    # Just like run_simple but takes user input after each step when requested by the model.\n",
    "    time_start = time.time()\n",
    "    state = {\"messages\": [(\"user\", user_input)]}\n",
    "    \n",
    "    # Continue processing until there is no new \"USER INPUT\" trigger.\n",
    "    while True:\n",
    "        user_input_triggered = False  # Flag to check if a \"USER INPUT\" prompt occurred.\n",
    "        for s in graph.stream(state, subgraphs=True):\n",
    "            if isinstance(s, tuple) and len(s) > 1:\n",
    "                # Display supervisor routing info if available.\n",
    "                if \"supervisor\" in s[1] and \"next\" in s[1][\"supervisor\"]:\n",
    "                    print(f\"Supervisor Next: {s[1]['supervisor']['next']}\")\n",
    "                    print(\"----\")\n",
    "                \n",
    "                # Extract agent messages.\n",
    "                agent_data = s[1].get(\"agent\")\n",
    "                if agent_data and \"messages\" in agent_data:\n",
    "                    for message in agent_data[\"messages\"]:\n",
    "                        model_name = message.response_metadata.get('model_name', 'Unknown')\n",
    "                        print(f\"Agent: {model_name}\")\n",
    "                        print(f\"Message: {message.content}\")\n",
    "                        time_end = time.time()\n",
    "                        print(f\"Time taken: {time_end - time_start}\")\n",
    "                        print(\"----\")\n",
    "                        # Check if the message contains a trigger for user input.\n",
    "                        if (\"USER INPUT NEEDED\" in message.content \n",
    "                            or \"REQUEST CLARIFICATION INPUT\" in message.content \n",
    "                            or \"INVALID\" in message.content):\n",
    "                            time.sleep(1)  # Small delay so that the message is visible.\n",
    "                            new_input = input(\"Enter your response: \")\n",
    "                            print(\"USER INPUT:\", new_input)\n",
    "                            print(\"----\")\n",
    "                            if new_input.lower() == \"exit\":\n",
    "                                return\n",
    "                            # Append the new user input to the existing messages for context.\n",
    "                            state[\"messages\"].append((\"user\", new_input))\n",
    "                            user_input_triggered = True\n",
    "                            # Break out of inner loop to resume streaming with the updated state.\n",
    "                            break\n",
    "                    if user_input_triggered:\n",
    "                        # Break out of the outer stream loop if we just received new input.\n",
    "                        break\n",
    "        # Exit the loop if no new input was triggered.\n",
    "        if not user_input_triggered:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervisor Next: Input_Checker\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: Creating a Value Proposition Canvas (VPC) for building wooden electric mini race cars involves identifying the customer segments, their needs, and how your product addresses those needs. Here's a refined version of your request:\n",
      "\n",
      "\"Create a Value Proposition Canvas for a business focused on building wooden electric mini race cars.\"\n",
      "\n",
      "ACCEPTED\n",
      "Time taken: 3.750638484954834\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: To create a Value Proposition Canvas for your business idea of building wooden electric mini race cars, we'll follow a structured process. Let's start with Step 1.\n",
      "\n",
      "### Step 1: Customization of Approach and Uniqueness/Nicheness of Customers\n",
      "\n",
      "Would you prefer a standard approach or a more creative approach for your business idea? A standard approach will focus on more common and general market segments while the creative approach will focus on niche or less well-known markets which might be smaller but also easier to target and saturate.\n",
      "\n",
      "USER INPUT NEEDED\n",
      "Time taken: 9.588006734848022\n",
      "----\n",
      "USER INPUT: I want a creative approach and a more guided mode for the VPC\n",
      "----\n",
      "Supervisor Next: Input_Checker\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: Create a Value Proposition Canvas (VPC) for building wooden electric mini race cars with a creative approach and guided mode. ACCEPTED\n",
      "Time taken: 47.38302445411682\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: Great! Let's start by customizing our approach to focus on niche customer segments and employ innovative strategies. Since you've chosen a guided mode, I'll handle most of the thinking and occasionally ask for your input. \n",
      "\n",
      "### Step 1: Customization of Approach and Uniqueness/Nicheness of Customers\n",
      "\n",
      "- **Creative Approach:** We'll target niche markets, such as eco-conscious hobbyists, educational institutions focusing on STEM, and collectors of unique racing memorabilia.\n",
      "\n",
      "Now, let's move on to understanding your business idea in more detail.\n",
      "\n",
      "### Step 2: Idea Understanding\n",
      "\n",
      "- **Business Idea:** Building wooden electric mini race cars.\n",
      "- **Intended Customers:** Eco-conscious hobbyists, educational institutions, and collectors.\n",
      "\n",
      "I will now perform a comprehensive web search to identify existing competitors, analyze their offerings, and gather current market trends related to your business idea. This will help us validate and refine your concept. Please hold on for a moment.\n",
      "Time taken: 53.10788178443909\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: ### Step 2: Idea Understanding (Continued)\n",
      "\n",
      "Based on the web search, here are some insights:\n",
      "\n",
      "1. **Market Trends:**\n",
      "   - Wooden race cars are popular as educational tools, enhancing creativity and hands-on skills.\n",
      "   - Electric mini race cars are gaining traction for their blend of power and precision, suitable for both competitive and casual use.\n",
      "   - The RC hobby has seen waves of popularity, indicating a potential market for innovative electric models.\n",
      "\n",
      "2. **Competitors:**\n",
      "   - There are existing products in the market, such as wooden race cars for educational purposes and electric mini race cars for hobbyists.\n",
      "   - The market for electric vehicles in racing is expanding, with a focus on cost-effectiveness and accessibility.\n",
      "\n",
      "With this understanding, let's proceed to identify any potential weaknesses and compare against existing solutions.\n",
      "\n",
      "### Step 3: Identify Weaknesses and Compare Against Existing Solutions\n",
      "\n",
      "- **Potential Weaknesses:**\n",
      "  - The market for wooden race cars is somewhat niche, primarily focused on educational and hobbyist segments.\n",
      "  - Electric mini race cars face competition from established RC models and other electric vehicles.\n",
      "\n",
      "- **Market Saturation:**\n",
      "  - The market is not overly saturated, but there are established players in both the wooden and electric mini race car segments.\n",
      "\n",
      "- **Challenges:**\n",
      "  - Differentiating the product in terms of design, functionality, and sustainability could be challenging.\n",
      "\n",
      "Given these insights, do you have any thoughts on how to address these challenges, or would you like me to suggest some strategies? \n",
      "\n",
      "USER INPUT NEEDED\n",
      "Time taken: 68.45674204826355\n",
      "----\n",
      "USER INPUT: I think I want the toy to be very premium and sustainable\n",
      "----\n",
      "Supervisor Next: Input_Checker\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: Create a Value Proposition Canvas (VPC) for building premium, sustainable wooden electric mini race cars. ACCEPTED\n",
      "Time taken: 99.9487476348877\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: To create a Value Proposition Canvas for your premium, sustainable wooden electric mini race cars, we'll follow a guided mode with a creative approach. This means I'll handle most of the thinking and only occasionally ask for your input, focusing on niche customer segments and innovative strategies. Let's begin with understanding your business idea and intended customers.\n",
      "\n",
      "### Step 2: Idea Understanding\n",
      "\n",
      "1. **Business Idea:**\n",
      "   - Building premium, sustainable wooden electric mini race cars.\n",
      "\n",
      "2. **Intended Customers:**\n",
      "   - Could you specify who you envision as your primary customers? Are they children, collectors, or perhaps environmentally conscious parents?\n",
      "\n",
      "Once I have this information, I'll proceed with a comprehensive web search to identify existing competitors, analyze their offerings, and gather current market trends related to your business idea. \n",
      "\n",
      "USER INPUT NEEDED\n",
      "Time taken: 105.85680365562439\n",
      "----\n",
      "USER INPUT: I like cats\n",
      "----\n",
      "Supervisor Next: Input_Checker\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: Create a Value Proposition Canvas (VPC) for building premium, sustainable wooden electric mini race cars. ACCEPTED\n",
      "Time taken: 123.05699872970581\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: To create a Value Proposition Canvas for your business idea of building premium, sustainable wooden electric mini race cars, we'll follow a structured process. Since you've chosen a creative approach and a more guided mode, I'll handle most of the thinking and occasionally ask for your input. Let's begin with Step 2: Idea Understanding.\n",
      "\n",
      "### Step 2: Idea Understanding\n",
      "\n",
      "- **Business Idea:** Building premium, sustainable wooden electric mini race cars.\n",
      "- **Intended Customers:** I will need to gather more information on this. \n",
      "\n",
      "I will now perform a comprehensive web search to identify existing competitors, analyze their offerings, and gather current market trends related to your business idea. This will help us understand the landscape and validate your concept. Please hold on for a moment.\n",
      "Time taken: 127.26705646514893\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: ### Analysis of Web Search Results\n",
      "\n",
      "1. **Market Trends:**\n",
      "   - There is a growing interest in sustainable vehicles, including electric cars with unique materials like wood. This aligns with your idea of using wood for mini race cars.\n",
      "   - The electric vehicle (EV) market is expanding, with a focus on sustainability and premium offerings.\n",
      "\n",
      "2. **Competitors:**\n",
      "   - While there are concepts like the Toyota Setsuna, which features a wooden body, the market for wooden electric mini race cars is not saturated, indicating a niche opportunity.\n",
      "   - The focus on premium and sustainable aspects can differentiate your product from existing electric vehicles.\n",
      "\n",
      "3. **Opportunities:**\n",
      "   - The premium and sustainable angle can attract environmentally conscious consumers who value unique and high-quality products.\n",
      "   - The novelty of wooden electric mini race cars can appeal to collectors and enthusiasts of unique vehicles.\n",
      "\n",
      "With this understanding, let's proceed to Step 3: Identify Weaknesses and Compare Against Existing Solutions. \n",
      "\n",
      "### Step 3: Identify Weaknesses and Compare Against Existing Solutions\n",
      "\n",
      "- **Potential Weaknesses:**\n",
      "  - High production costs due to premium materials and sustainable practices.\n",
      "  - Limited market size for niche products.\n",
      "  - Challenges in achieving performance standards expected from race cars.\n",
      "\n",
      "- **Comparison Against Existing Solutions:**\n",
      "  - Unlike traditional electric vehicles, your product offers a unique combination of sustainability and premium craftsmanship.\n",
      "  - The use of wood as a primary material can be a selling point for eco-conscious consumers.\n",
      "\n",
      "Would you like to address any of these potential challenges, or should we proceed to the next step? \n",
      "\n",
      "USER INPUT NEEDED\n",
      "Time taken: 144.16417121887207\n",
      "----\n",
      "USER INPUT: How can I bake a choclate cake without an oven\n",
      "----\n",
      "Supervisor Next: Input_Checker\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: [SORRY, INPUT DEVIATES FROM TASK. PLEASE TRY AGAIN]\n",
      "Time taken: 165.38558959960938\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: I'm here to help you create a Value Proposition Canvas for your business idea. Let's stay focused on that. How would you like to proceed with your VPC? \n",
      "\n",
      "Since you've chosen a creative approach and a more guided mode, I'll focus on niche customer segments and handle most of the thinking, occasionally asking for your input. Let's start by understanding your business idea and intended customers.\n",
      "\n",
      "### Step 2: Idea Understanding\n",
      "\n",
      "- **Your Business Idea:** Building premium, sustainable wooden electric mini race cars.\n",
      "- **Intended Customers:** Could you provide more details on who you envision as your target customers? Are they collectors, parents looking for unique toys, or another group?\n",
      "\n",
      "Once I have this information, I'll proceed with a web search to gather insights on competitors and market trends. USER INPUT NEEDED\n",
      "Time taken: 175.46873450279236\n",
      "----\n",
      "USER INPUT: \n",
      "----\n",
      "Supervisor Next: Input_Checker\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: [SORRY, INPUT DEVIATES FROM TASK. PLEASE TRY AGAIN]\n",
      "Time taken: 187.91498184204102\n",
      "----\n",
      "Agent: gpt-4o-2024-08-06\n",
      "Message: I'm here to help you create a Value Proposition Canvas for your business idea. Let's stay focused on that. How would you like to proceed with your VPC? \n",
      "\n",
      "Since you've chosen a creative approach and a more guided mode, I'll focus on niche customer segments and handle most of the thinking, occasionally asking for your input. Let's start by understanding your business idea in more detail.\n",
      "\n",
      "**Step 2: Idea Understanding**\n",
      "\n",
      "Could you please provide more details about your business idea for building wooden electric mini race cars? Specifically, who are your intended customers? \n",
      "\n",
      "USER INPUT NEEDED\n",
      "Time taken: 191.539217710495\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "run_iter(\"Create me a VPC for an for building wooden electric mini race cars\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
